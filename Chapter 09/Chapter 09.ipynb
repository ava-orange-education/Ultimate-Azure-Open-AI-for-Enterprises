{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9a80f-e0da-41fa-8480-52ad28a43534",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real-time speech is recognized from a microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39597-6d3b-4e4b-983f-5e94eab53809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def real_time_speech_to_text():\n",
    "    #########################\n",
    "    #Speech Configuration\n",
    "    ##########################\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('XXXX'), region=os.environ.get('XXXX'))\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "    ############################################################\n",
    "    #Audio Configuration - setting laptop or desktop as default_microphone\n",
    "   #############################################################\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer =speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "   print(\"########################\")\n",
    "   print(\"Please turn on your microphone and speak\")\n",
    "   print(\"#########################\")\n",
    "   \n",
    "  #################################\n",
    "  # Get the audio from the mic\n",
    "  #################################\n",
    "  speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "\n",
    "   ####################\n",
    "   # Audio analysis\n",
    "    ####################\n",
    "\n",
    "    # 1. Recognized the Speech\n",
    "    if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(speech_recognition_result.text))\n",
    "    # 2. Speech not recognized\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(speech_recognition_result.no_match_details))\n",
    "    # 3. Speech cancelled\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_recognition_result.cancellation_details\n",
    "        print(\"Speech Recognition cancelled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n",
    "# Calling the function \n",
    "real_time_speech_to_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514b332-b80f-4c72-8c75-ac374ebd3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Speech recognizes from a stored file locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482496b7-ae4f-4f88-bc12-28fb35e0ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def real_time_speech_to_text():\n",
    "    #########################\n",
    "    #Speech Configuration\n",
    "    ##########################\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('XXXX'), region=os.environ.get('XXXX'))\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "    ############################################################\n",
    "    #Audio Configuration - setting laptop or desktop as default_microphone\n",
    "   #############################################################\n",
    "   audio_config = speechsdk.audio.AudioConfig(filename=\"C:\\xxxxx\\xxxxx\\abc.wav\")\n",
    "   speech_recognizer =speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "   print(\"#######################\")\n",
    "   print(\" Start Listening to the audio from the file.\")\n",
    "   print(\"#######################\")\n",
    "   \n",
    "  #################################\n",
    "  # Get the audio from the mic\n",
    "  #################################\n",
    "  speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "\n",
    "   ####################\n",
    "   # Audio analysis\n",
    "    ####################\n",
    "\n",
    "    # 1. Recognized the Speech from an audio file\n",
    "    if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(speech_recognition_result.text))\n",
    "    # 2. Speech not recognized from an audio file\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(speech_recognition_result.no_match_details))\n",
    "    # 3. Speech cancelled due to audio file disturbance \n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_recognition_result.cancellation_details\n",
    "        print(\"Speech Recognition cancelled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n",
    "# Calling the function \n",
    "real_time_speech_to_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8af0e-48f6-445f-b672-e517b4569542",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real-time Convert text-to-speech implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f1ba2-0df6-4a17-b689-6b532d36dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "#########################\n",
    "#Speech Configuration\n",
    "##########################\n",
    "my_speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('XX'), region=os.environ.get('XX'))\n",
    "\n",
    "######################################\n",
    "#Mentioning audio output configuration \n",
    "#####################################\n",
    "my_audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "#########################################\n",
    "# Make the application understand the input text of different languages.\n",
    "#########################################\n",
    "my_speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "my_speech_synthesizer=speechsdk.SpeechSynthesizer(speech_config=my_speech_config, my_audio_config=audio_config)\n",
    "\n",
    "print(\"###################\")\n",
    "print(\"Please enter the text that you want to speak <...>\")\n",
    "print(\"###################\")\n",
    "text = input()\n",
    "\n",
    "my_speech_synthesis_result = my_speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "###################\n",
    "# Text analysis\n",
    "###################\n",
    "\n",
    "    # 1. Recognized the Speech\n",
    "if my_speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "    # 2. Speech cancelled\n",
    "elif my_speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = my_speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430f0a3-9944-4baa-9f04-f06ef85a95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real-time speech is recognized from a microphone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccabeaf-699f-42fe-a917-bdf739a2fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"“##################\"”)\n",
    "print(\"“Import libraries\"”)\n",
    "print(\"“###############\"”)\n",
    "import os\n",
    "from azure.ai.vision.image analysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from the azure. Core.credentials import AzureKeyCredential\n",
    "\n",
    "#########################\n",
    "#Vision Configuration\n",
    "##########################\n",
    "try:\n",
    "    endpoint = os.environ[\"“VISION_ENDPOINT\"”]\n",
    "    key = os.environ[\"“VISION_KEY\"”]\n",
    "except KeyError:\n",
    "    print(\"“Mandatory fields are missing '‘VISION_ENDPOINT'’ or '‘VISION_KEY '‘\"”)\n",
    "    exit()\n",
    "\n",
    "# Create an Image Analysis client\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "print(\"“##############################\"”)\n",
    "print(\"“# Get a caption for the image.\"”)\n",
    "print(\"“##############################\"”)\n",
    "\n",
    "\n",
    "result = client.analyze_from_url(\n",
    "    image_url=\"”XXXXXXXXXXXXX\"”,visual_features=[VisualFeatures.CAPTION, VisualFeatures.READ],\n",
    "    gender_neutral_caption=True,  # Optional (default is False))\n",
    "\n",
    "print(\"“##############################\"”)\n",
    "print(\"“Azure Vision -– Image analysis:\"”)\n",
    "print(\"“##############################\"”)\n",
    "\n",
    "print(\"“ Caption For the given image is:\"”)\n",
    "if the result. Caption is not None:\n",
    "    print(f\"”   '‘{result.caption.text}'’, Confidence {result.caption.confidence:.4f}\"”)\n",
    "\n",
    "print(\"“##############################\"”)\n",
    "print(\"“ OCR analysis results:\"”)\n",
    "print(\"“##############################\"”)\n",
    "\n",
    "print(\"“ Read:\"”)\n",
    "if the result. Read is not None:\n",
    "    for line in result.read.blocks[0].lines:\n",
    "            print(f\"”     Word: '‘{word.text}'’, Bounding polygon {word.bounding_polygon}, Confidence {word.confidence:.4f}\"”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76a62e-a256-47e2-87eb-a042b06c60b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
